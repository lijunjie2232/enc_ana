{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TimeSeriesTransformerConfig, TimeSeriesTransformerModel\n",
    "from mamba_ssm import Mamba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a Time Series Transformer configuration with 12 time steps for prediction\n",
    "configuration = TimeSeriesTransformerConfig(prediction_length=60*5)\n",
    "\n",
    "# Randomly initializing a model (with random weights) from the configuration\n",
    "tst_model = TimeSeriesTransformerModel(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = tst_model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeSeriesTransformerModel(\n",
       "  (scaler): TimeSeriesMeanScaler()\n",
       "  (encoder): TimeSeriesTransformerEncoder(\n",
       "    (value_embedding): TimeSeriesValueEmbedding(\n",
       "      (value_projection): Linear(in_features=9, out_features=64, bias=False)\n",
       "    )\n",
       "    (embed_positions): TimeSeriesSinusoidalPositionalEmbedding(600, 64)\n",
       "    (layers): ModuleList(\n",
       "      (0): TimeSeriesTransformerEncoderLayer(\n",
       "        (self_attn): TimeSeriesTransformerAttention(\n",
       "          (k_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (v_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (q_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (activation_fn): GELUActivation()\n",
       "        (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
       "        (fc2): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (final_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): TimeSeriesTransformerEncoderLayer(\n",
       "        (self_attn): TimeSeriesTransformerAttention(\n",
       "          (k_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (v_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (q_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (activation_fn): GELUActivation()\n",
       "        (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
       "        (fc2): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (final_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layernorm_embedding): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): TimeSeriesTransformerDecoder(\n",
       "    (value_embedding): TimeSeriesValueEmbedding(\n",
       "      (value_projection): Linear(in_features=9, out_features=64, bias=False)\n",
       "    )\n",
       "    (embed_positions): TimeSeriesSinusoidalPositionalEmbedding(600, 64)\n",
       "    (layers): ModuleList(\n",
       "      (0): TimeSeriesTransformerDecoderLayer(\n",
       "        (self_attn): TimeSeriesTransformerAttention(\n",
       "          (k_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (v_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (q_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): TimeSeriesTransformerAttention(\n",
       "          (k_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (v_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (q_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
       "        (fc2): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (final_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): TimeSeriesTransformerDecoderLayer(\n",
       "        (self_attn): TimeSeriesTransformerAttention(\n",
       "          (k_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (v_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (q_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): TimeSeriesTransformerAttention(\n",
       "          (k_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (v_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (q_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
       "        (fc2): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (final_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layernorm_embedding): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mamba2_model = Mamba2(\n",
    "    # This module uses roughly 3 * expand * d_model^2 parameters\n",
    "    d_model=128, # Model dimension d_model\n",
    "    d_state=64,  # SSM state expansion factor, typically 64 or 128\n",
    "    d_conv=4,    # Local convolution width\n",
    "    expand=2,    # Block expansion factor\n",
    "    headdim=32,  # Head dimension, typically 64 or 128\n",
    ").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mamba2(\n",
       "  (in_proj): Linear(in_features=128, out_features=648, bias=False)\n",
       "  (conv1d): Conv1d(384, 384, kernel_size=(4,), stride=(1,), padding=(3,), groups=384)\n",
       "  (act): SiLU()\n",
       "  (norm): RMSNorm()\n",
       "  (out_proj): Linear(in_features=256, out_features=128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mamba2_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch, length, dim = 2, 256, 128\n",
    "x = torch.randn(batch, length, dim).to(\"cuda\")\n",
    "y = mamba2_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256, 128])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeSeriesTransformerEncoderLayer(\n",
       "  (self_attn): TimeSeriesTransformerAttention(\n",
       "    (k_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (v_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (q_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "  )\n",
       "  (self_attn_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  (activation_fn): GELUActivation()\n",
       "  (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=64, bias=True)\n",
       "  (final_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_model.encoder.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_attn = tst_model.encoder.layers[0].self_attn.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 256, 64).to(\"cuda\")\n",
    "y = tst_attn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 64])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Mamba2Model, Mamba2ForCausalLM, Mamba2PreTrainedModel\n",
    "from transformers.models.mamba2.configuration_mamba2 import Mamba2Config\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_config = Mamba2Config()\n",
    "m2_llm = Mamba2ForCausalLM(m2_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mamba2ForCausalLM(\n",
       "  (backbone): Mamba2Model(\n",
       "    (embeddings): Embedding(32768, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (12): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (13): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (14): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (15): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (16): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (17): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (18): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (19): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (20): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (21): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (22): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (23): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (24): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (25): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (26): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (27): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (28): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (29): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (30): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (31): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (32): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (33): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (34): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (35): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (36): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (37): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (38): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (39): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (40): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (41): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (42): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (43): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (44): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (45): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (46): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (47): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (48): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (49): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (50): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (51): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (52): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (53): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (54): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (55): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (56): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (57): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (58): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (59): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (60): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (61): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (62): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (63): Mamba2Block(\n",
       "        (norm): Mamba2RMSNorm()\n",
       "        (mixer): Mamba2Mixer(\n",
       "          (act): SiLU()\n",
       "          (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "          (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "          (norm): MambaRMSNormGated()\n",
       "          (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm_f): Mamba2RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32768, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_backbone = m2_llm.backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMamba2Config(Mamba2Config):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "        num_heads (`int`, *optional*, defaults to 128):\n",
    "            Number of heads for the evolution matrices of mamba 2.\n",
    "        head_dim (`int`, *optional*, defaults to 64):\n",
    "            Dimension of each head.\n",
    "        vocab_size (`int`, *optional*, defaults to 32768):\n",
    "            Vocabulary size of the MAMBA2 model. Defines the number of different tokens that can be represented by the\n",
    "            `inputs_ids` passed when calling [`Mamba2Model`].\n",
    "        hidden_size (`int`, *optional*, defaults to 4096):\n",
    "            Dimensionality of the embeddings and hidden states.\n",
    "        state_size (`int`, *optional*, defaults to 128): shape of the state space latents.\n",
    "        num_hidden_layers (`int`, *optional*, defaults to 64):\n",
    "            Number of hidden layers in the model.\n",
    "        layer_norm_epsilon (`float`, *optional*, defaults to 1e-05):\n",
    "            The epsilon to use in the layer normalization layers.\n",
    "        pad_token_id (`int`, *optional*, defaults to 1):\n",
    "            Padding token id.\n",
    "        bos_token_id (`int`, *optional*, defaults to 0):\n",
    "            The id of the beginning of sentence token in the vocabulary.\n",
    "        eos_token_id (`int`, *optional*, defaults to 2):\n",
    "            The id of the end of sentence token in the vocabulary.\n",
    "        expand (`int`, *optional*, defaults to 2): Expanding factor used to determine the intermediate size.\n",
    "        conv_kernel (`int`, *optional*, defaults to 4): Size of the convolution kernel.\n",
    "        n_groups (`int`, *optional*, defaults to 8):\n",
    "            Number of groups for the evolution matrices of mamba 2.\n",
    "        use_bias (`bool`, *optional*, defaults to `False`):\n",
    "            Whether or not to use bias in [\"in_proj\", \"out_proj\"] of the mixer block\n",
    "        use_conv_bias (`bool`, *optional*, defaults to `True`):\n",
    "            Whether or not to use bias in the convolution layer of the mixer block.\n",
    "        hidden_act (`str`, *optional*, defaults to `\"silu\"`):\n",
    "            The non-linear activation function (function or string) in the decoder.\n",
    "        initializer_range (`float`, *optional*, defaults to 0.1):\n",
    "            The standard deviation of the truncated_normal_initializer for initializing all weight matrices.\n",
    "        residual_in_fp32 (`bool`, *optional*, defaults to `True`):\n",
    "            Whether or not residuals should be in `float32`. If set to `False` residuals will keep the same `dtype` as the rest of the model\n",
    "        time_step_rank (`Union[int,str]`, *optional*, defaults to `\"auto\"`):\n",
    "            Rank of the discretization projection matrix. `\"auto\"` means that it will default to `math.ceil(self.hidden_size / 16)`\n",
    "        time_step_min (`float`, *optional*, defaults to 0.001):\n",
    "            Minimum `time_step` used to bound `dt_proj.bias`.\n",
    "        time_step_max (`float`, *optional*, defaults to 0.1):\n",
    "            Maximum `time_step` used to bound `dt_proj.bias`.\n",
    "        time_step_floor (`float`, *optional*, defaults to 0.0001):\n",
    "            Minimum clamping value of the `dt_proj.bias` layer initialization.\n",
    "        time_step_limit (`tuple`, *optional*, defaults to `(0.0, inf)`):\n",
    "            Accepted range of time step values.\n",
    "        rescale_prenorm_residual (`bool`, *optional*, defaults to `False`):\n",
    "            Whether or not to rescale `out_proj` weights when initializing.\n",
    "        use_cache (`bool`, *optional*, defaults to `True`):\n",
    "            Whether or not the cache should be used.\n",
    "        rms_norm (`bool`, *optional*, defaults to `True`):\n",
    "            Whether to use RMS norm or not.\n",
    "        chunk_size (`int`, *optional*, defaults to 256):\n",
    "            Size of the chunks that will comprise the sequence.\n",
    "        tie_word_embeddings (`bool`, *optional*, defaults to `False`):\n",
    "            Whether to tie word embeddings or not.\n",
    "    \"\"\"\n",
    "    model_type = \"mamba2\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        symbol_size=32768,\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ):\n",
    "        self.symbol_size = symbol_size\n",
    "        super().__init__(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mamba2Model(\n",
       "  (embeddings): Embedding(32768, 4096)\n",
       "  (layers): ModuleList(\n",
       "    (0): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (4): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (5): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (6): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (7): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (8): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (9): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (10): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (11): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (12): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (13): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (14): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (15): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (16): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (17): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (18): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (19): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (20): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (21): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (22): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (23): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (24): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (25): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (26): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (27): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (28): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (29): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (30): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (31): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (32): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (33): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (34): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (35): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (36): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (37): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (38): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (39): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (40): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (41): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (42): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (43): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (44): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (45): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (46): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (47): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (48): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (49): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (50): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (51): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (52): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (53): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (54): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (55): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (56): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (57): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (58): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (59): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (60): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (61): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (62): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (63): Mamba2Block(\n",
       "      (norm): Mamba2RMSNorm()\n",
       "      (mixer): Mamba2Mixer(\n",
       "        (act): SiLU()\n",
       "        (conv1d): Conv1d(10240, 10240, kernel_size=(4,), stride=(1,), padding=(3,), groups=10240)\n",
       "        (in_proj): Linear(in_features=4096, out_features=18560, bias=False)\n",
       "        (norm): MambaRMSNormGated()\n",
       "        (out_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm_f): Mamba2RMSNorm()\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyMamba2Model(Mamba2PreTrainedModel):\n",
    "    def __init__(self, config:MyMamba2Config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.symbol_emb = nn.Embedding(config.symbol_size, config.hidden_size)\n",
    "        \n",
    "        self.layers = nn.ModuleList([Mamba2Block(config, layer_idx=idx) for idx in range(config.num_hidden_layers)])\n",
    "\n",
    "        self.gradient_checkpointing = False\n",
    "        self.norm_f = Mamba2RMSNorm(config.hidden_size, eps=config.layer_norm_epsilon)\n",
    "        # Initialize weights and apply final processing\n",
    "        self._register_load_state_dict_pre_hook(self.load_hook)\n",
    "        self.post_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "manba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
